<!DOCTYPE html>
<html>
  <head>
    <title>Współbieżność w Ruby [Gdańsk, TRUG, 2012-05-15]</title>

    <meta charset='utf-8'>
    <script src="./slides.js"></script>
    <style type="text/css">
      article {
        padding-top: 40px;
      }
      h1.small {
        font-size: 50px;
      }
      article h3 {
        padding-top: 30px;
      }
      article a {
        text-decoration: none !important;
      }
      article q {
        font-size: 30px;
        line-height: 40px;
      }
    </style>
  </head>
    <body style='display: none'>

    <section class='slides layout-regular template-default'>

      <article>
        <h1>Współbieżność w Ruby</h1>
        <p>
        Trójmiejska Grupa Użytkowników Ruby<br>
        Gdańsk, 15 Maja 2012
        </p>
      </article>

      <article>
        <h1 class="small">Paweł Gościcki</h1>
        <p>
        <a href="http://pawelgoscicki.com/">pawelgoscicki.com</a><br>
        <a href="https://twitter.com/pawelgoscicki">@pawelgoscicki</a><br>
        <a href="https://github.com/pjg">github.com/pjg</a>
        </p>

        <br>

        <p><a href="http://www.exvo.com">Exvo.com</a></p>
      </article>

      <article>
        <h3>Wspołbieżność?</h3>
        <q><strong>Przetwarzanie współbieżne</strong> (ang. <em>concurrent computing</em>) – przetwarzanie oparte na współistnieniu wielu wątków lub procesów, operujących na współdzielonych danych. Wątki uruchomione na tym samym procesorze są przełączane w krótkich przedziałach czasu, co sprawia wrażenie, że wykonują się równolegle.</q>

        <p>-- <a href="http://pl.wikipedia.org/wiki/Przetwarzanie_wsp%C3%B3%C5%82bie%C5%BCne">http://pl.wikipedia.org/wiki/Przetwarzanie_współbieżne</a></p>
      </article>

      <article>
        <h3>Czemu jest to ważne? (I)</h3>
        <p>
        <img style="width: 60%" src="images/cpu.png">
        </p>
      </article>

      <article>
        <h3>Czemu jest to ważne? (II)</h3>
        <q>Free Lunch is over</q>
        <p>-- Herb Sutter, <a href="http://www.gotw.ca/publications/concurrency-ddj.htm">http://www.gotw.ca/publications/concurrency-ddj.htm</a></p>
        <p>W 2003 roku zatrzymał się wzrost GHz, ale liczba tranzystorów ciągle rośnie z roku na rok.</p>
        <p>Powód? Wprowadzenie wielordzeniowych procesorów.</p>
      </article>

      <article>
        <h3>Nowy miernik</h3>
        <h1>Wydajność w przeliczeniu na 1W (TDP)</h1>
        <p>(tutaj prawo Moore'a nadal znajduje zastosowanie)</p>
      </article>

      <article>
        <h1>Co to znaczy dla nas?</h1>
        <p>Dla <em>nas</em>, twórców aplikacji webowych.</p>
      </article>

      <article>
        <h1>Może znaczyć "nic"</h1>
        <p>Serwery aplikacji są właściwie bez stanu (stan przechowywany jest w sesji u klienta, każdy request może być obsługiwany przez inny proces/maszynę).</p>
        <p>Możemy się skalować horyzontalnie dodając nowe serwery aplikacji.</p>
      </article>

      <article>
        <h1>Tylko pojawiają się problemy...</h1>
        <ul class="build">
          <li>Jeden proces serwera aplikacji <code>~150MB</code></li>
          <li>Chcemy obsługiwać 100 requestów jednocześnie? <code>15GB</code> RAM trzeba...</li>
          <li>RAM jest tani... (póki nie trzeba go podwajać co jakiś czas)</li>
        </ul>
      </article>

      <article>
        <h3>Na początek trochę teorii... (I)</h3>
        <br>
        <h4>PROCES</h4>
        <ul class="build">
          <li>Definiuje się jako <em>egzemplarz wykonywanego programu</em></li>
          <li>Każdy działający program uruchamia (co najmniej) jeden proces</li>
          <li>Każdy proces może tworzyć nowe procesy (kopie siebie) funkcją <code>fork()</code> - niczego nie współdzieląc</li>
          <li>Czyli nową pamięć trzeba zarezerwować dla nowego procesu (problem wspomnianych <code>15GB</code> ramu)</li>
        </ul>
      </article>

      <article>
        <h3>Na początek trochę teorii... (II)</h3>
        <br>
        <h4>Passenger/Unicorn</h4>
        <ul class="build">
          <li>Dynamiczne skalowanie - gdy jest zapotrzebowanie (więcej requestów), to jest uruchamianych więcej procesów serwera aplikacji, gdy mniej to procesy są zabijane</li>
          <li>Używają systemowego (Linux/Unix) polecenia <code>fork()</code>, starając się wykorzystywać <em>copy on write</em> tzn. pamięć nowego procesu dziecka jest kopiowana tylko w momencie, gdy zostaje zmieniona</li>
          <li>Oczywiście w modelach/kontrolerach ładujemy sporo obiektów, więc pamięć będzie się zwiększać, ale część pozostanie współdzielona</li>
          <li>Słabe wsparcie w Ruby (1.8.7 REE i 2.0+ MRI) (<em>garbage collector</em>)</li>
          <li>Bardzo popularne rozwiązanie pozwalające trochę efektywniej używać dostępne rdzenie/procesory</li>
        </ul>
      </article>

      <article>
        <h1>I na tym właściwie mógłbym zakończyć swoją prezentację</h1>
        <p style="text-align: right; margin-top: 45px"><img style="width: 250px" src="images/trollface.jpg"></p>
      </article>

      <article>
        <h3>Na początek trochę teorii... (III)</h3>
        <br>
        <h4>WĄTEK (thread)</h4>
        <ul class="build">
          <li>Wątek działa w kontekście procesu</li>
          <li>Nowy wątek dzieli wszystkie zasoby zarezerwowane dla danego procesu (m.in. współdzieli otwarte pliki, gniazda, pamięć z wątkiem, który go wywołał, czyli może zmieniać te same zmienne)</li>
          <li>W Ruby narzut (<em>overhead</em>) jednego wątku to <strong>tylko</strong> <code>~2KB</code></li>
          <li>Przełączanie się między wątkami jest szybsze niż przełączanie się między procesami</li>
          <li>Używając wątków kontrolowanych przez sytem operacyjny (o czym za chwilę) możemy wykonywać kod współbieżnie na wielu rdzeniach/procesorach</li>
          <li>"Zarządca" może w każdej chwili przerwać jeden wątek i przełączyć się na kolejny</li>
        </ul>
      </article>

      <article>
        <h3>Na początek trochę teorii... (IV)</h3>
        <br>
        <h4>WADY WĄTKÓW</h4>
        <ul class="build">
          <li>Komunikacja przez współdzieloną pamięć - trzeba używać blokad, muteksów (algorytmów wzajemnego wykluczania)</li>
          <li>Łatwo spowodować korupcję danych</li>
          <li>Możliwość wystąpienia zakleszczeń (<em>deadlocks</em>) - pierwszy wątek czeka na zakończenie drugiego, a drugi na pierwszego (sytuacja spotykana w bazach danych)</li>
          <li>Większe skomplikowanie kodu</li>
          <li>Niedeterministyczne zachowanie kodu (trudno jest być 100% pewnym jak dokładnie zachowają się wątki wykonywane współbieżnie) - bardzo trudno jest pisać testy wykrywające wyścigi (chociaż jest to możliwe...)</li>
        </ul>
      </article>

      <article>
        <h1>A jak to się robi w Ruby?</h1>
      </article>

      <article>
        <h3>Zielone wątki (ang. <em>green threads</em>)</h3>
        <ul class="build">
          <li>Istnieją w Ruby z linii 1.8</li>
          <li>obsługiwane przez VM Ruby'iego (a nie przez system operacyjny)</li>
          <li>takie samo zachowanie (ujednolicone) na różnych platformach (systemach operacyjnych) (bez optymalizacji)</li>
          <li>szybsze uruchamianie, mniejszy narzut pamięci (niż natywne wątki, o których za chwilę)</li>
          <li>nie wykonują się współbieżne (limit 1 procesora)</li>
          <li>operacje I/O blokują inne wątki (czyli trzeba czekać na odczyt danych z bazy danych)</li>
          <li>14 lat temu Matz prawidłowo stwierdził, że to wystarczy (wtedy nie było wieloprocesorowych systemów)</li>
        </ul>
      </article>

      <article>
        <h3>Natywne wątki (ang. <em>native threads</em>)</h3>
        <ul class="build">
          <li>Ruby linii 1.9</li>
          <li>obsługiwane bezpośrednio przez system operacyjny (Ruby ma mniej pracy)</li>
          <li>mogą się wykonywać na wielu procesorach jednocześnie</li>
          <li>operacje I/O <strong>nie blokują</strong> innych wątków (większość obecnych gemów Railsowych nie blokuje Ruby'iego)</li>
          <li>tylko <code>~2KB</code> narzutu na każdy wątek</li>
        </ul>
      </article>

      <article>
        <h3>Fibers/continuations</h3>
        <ul class="build">
          <li>Ruby linii 1.9</li>
          <li>"lekkie wątki"</li>
          <li>do zadań programisty należy przełączanie się między wątkami (czyli decyzje o tym kiedy przerwać wątek i uruchomić kolejny) (a nie do zarządcy)</li>
          <li>wiemy kiedy takie wątki startują i się zatrzymują, więc nie mamy problemów związanych z korupcją danych</li>
          <li>podobnie jak z zielonymi wątkami operacje I/O blokują inne wątki</li>
        </ul>
      </article>

      <article>
        <h3>GIL - Global Interpreter Lock</h3>
        <ul class="build">
          <li>aby zapobiegać korupcji danych, w danym momencie czasu tylko 1 wątek może "rozmawiać" z VM Ruby'iego</li>
          <li>czyli nie możemy rodzielić pracy na wiele procesorów...</li>
          <li>(inne języki interpretowane, jak np. Python też mają odpowiednik GILa)</li>
          <li>nie można doprowadzić do korupcji danych (życie programistów staje się łatwiejsze)</li>
          <li>nie ma wyścigów (race conditions)</li>
          <li>część Ruby MRI jest napisana w C i nie jest "thread safe" (np. Hash)</li>
          <li>niektóre implementacje Ruby nie mają GILa (JRuby/Rubinius/MacRuby)</li>
        </ul>
      </article>

      <article>
        <h3>To może usuńmy GIL?</h3>
        <ul class="build">
          <li>część rozszerzeń pisana w C przestanie działać (wiele rzeczy... i core i stdlib i gemy)</li>
          <li>ogólnie - zbyt dużo roboty / zbyt duża zmiana</li>
          <li>pisanie rozszerzeń w C staje się dużo trudniejsze (blokady zapisu), a tak napisane rozszerzenia będą wolniejsze</li>
          <li>Ruby nie jest taki wolny - ograniczenie I/O a nie CPU (zazwyczaj czekamy na zakończenie operacji I/O a nie obliczeń) (podobnie node.js, EventedMachine, Reactor pattern)</li>
        </ul>
      </article>

      <article>
        <h1>Analogia do kaloszy</h1>
        <p>Jeżeli nie pada, to czemu mamy je codziennie nosić?</p>
        <p></p>
      </article>

      <article>
        <q>The main concern is safeness. We cannot remove the GIL because then it would allow the C Ruby code to crash when you use threads. I don't want Ruby to be like that.</q>
        <p>-- Matz @ RubyConf '2011-10, New Orleans</p>
      </article>

      <article>
        <h3>To jak radzą sobie JRuby/Rubinius?</h3>
        <ul class="build">
          <li>JRuby/Rubinius przepisały sporą część Ruby'iego (głównie rzeczy napisane w C), tak aby osiągnąć "thread safety"</li>
          <li>Niektóre gemy nie działają, o części w ogóle nie wiadomo czy działają czy nie</li>
          <li>Co innego jest działanie pod JRuby/Rubiniusem, a co innego bycie "thread safe"</li>
          <li>Z drugiej strony np. w JRuby jak coś nie działa z Ruby'iego, to można wziąć jakąś bibliotekę Javy</li>
          <li>No to używajmy JRuby! (ew. Rubiniusa)</li>
        </ul>
      </article>

      <article>
        <h1>Ale...</h1>
        <p>Współbieżność jest trudna.</p>
        <p>Wydaje się, że już ją umiesz, że wszystko się kuma, ale napotykasz na wyścig (ang. <em>race condition</em>) -- sytuacja, że kod wykonuje się wcześniej niż zakładaliśmy -- np. przed zakończeniem innego kodu), który teoretycznie nie jest możliwy, ale jednak ma miejsce i wszystko wywraca się do góry nogami.</p>
      </article>

      <article>
        <h3>Przykład</h3>
        <section>
          <pre>
@array, threads = [], []
4.times do
  threads &lt;&lt; Thread.new { (1..100_000).each { |n| @array &lt;&lt; n } }
end
threads.each { |t| t.join }
puts @array.size
          </pre>

          <ul class="build">
            <li>MRI: <code>400000</code></li>
            <li>JRuby: <code>335467, 342397, 341080</code></li>
            <li>MRI: <code>294278, 285755, 280704</code></li>
          </ul>
        </section>
      </article>

      <article>
        <h1>A co z Rails?</h1>
        <p>I z MRI?</p>
      </article>

      <article>
        <h3>Mamy coś "za darmo" (dokładniej: współbieżność przy wykonywaniu I/O)</h3>
        <p>Gemfile:</p>
        <section style="margin-top: -30px">
          <pre>gem "mysql2"</pre>
        </section>

        <p>config/database.yml</p>
        <section style="margin-top: -30px">
<pre>
development:
  adapter: mysql2
  pool: 20
  ...
</pre>
        </section>

        <p>routes.rb</p>
        <section style="margin-top: -30px">
          <pre>root :to =&gt; 'site#index'</pre>
        </section>
      </article>

      <article>
        <section>
          <pre>
class SiteController &lt; ApplicationController
  def index
    threads = []
    10.times do |n|
      threads &lt;&lt; Thread.new do
        ActiveRecord::Base.connection_pool.with_connection do |conn|
          res = conn.execute(&quot;SELECT SLEEP(1)&quot;)
        end
      end
    end
    threads.each { |t| t.join }
  end
end
          </pre>
        </section>

        <section>
<pre>
☺ rails s
=&gt; Booting WEBrick
=&gt; Rails 3.2.3 application starting in development on http://0.0.0.0:3000
=&gt; Call with -d to detach
</pre>
</section>
      </article>

      <article class="smaller">
        <section>
<pre>
☺ ab -c 1 -n 1 http://localhost:3000/
...
Requests per second:    0.99 [#/sec] (mean)
Time per request:       1013.341 [ms] (mean)
Time per request:       1013.341 [ms] (mean, across all concurrent requests)
</pre>
</section>

<section>
<pre>
Started GET &quot;/&quot; for 127.0.0.1 at 2012-05-13 20:05:19 +0200
Processing by SiteController#index as */*
   (1007.0ms)  SELECT SLEEP(1)
   (1003.1ms)  SELECT SLEEP(1)
   (1005.1ms)  SELECT SLEEP(1)
   (1001.4ms)  SELECT SLEEP(1)
   (1000.2ms)  SELECT SLEEP(1)
   (1000.2ms)  SELECT SLEEP(1)
   (1000.2ms)  SELECT SLEEP(1)
   (1000.2ms)  SELECT SLEEP(1)
   (1000.2ms)  SELECT SLEEP(1)
   (1000.2ms)  SELECT SLEEP(1)
  Rendered site/index.html.erb within layouts/application (1.3ms)
Completed 200 OK in 1066ms (Views: 39.8ms | ActiveRecord: 0.0ms)
          </pre>
        </section>
      </article>

      <article>
        <h1><code>config.threadsafe!</code></h1>
        <br>
        <p>Rails 2.2+</p>
      </article>

      <article>
        <p>config/database.yml</p>
        <section>
<pre>
development:
  adapter: mysql2
  pool: 20
  ...
</pre>
        </section>

        <p>config/environments/development.rb</p>
        <section>
<pre>
config.threadsafe!
</pre>

        </section>
      </article>

      <article>
        <section>
<pre>
class SiteController &lt; ApplicationController
  def index
    ActiveRecord::Base.connection_pool.with_connection do |conn|
      res = conn.execute(&quot;SELECT SLEEP(1)&quot;)
    end
  end
end
</pre>
        </section>

        <section>
          <pre>
☺ r s
=&gt; Booting WEBrick
=&gt; Rails 3.2.3 application starting in development on http://0.0.0.0:3000
=&gt; Call with -d to detach
=&gt; Ctrl-C to shutdown server
[2012-05-13 21:25:46] INFO  WEBrick 1.3.1
[2012-05-13 21:25:46] INFO  ruby 1.9.3 (2012-04-20) [x86_64-linux]
[2012-05-13 21:25:46] INFO  WEBrick::HTTPServer#start: pid=28954 port=3000
          </pre>
        </section>
      </article>

      <article class="smaller">
        <section>
          <pre>
☺ ab -c 10 -n 10 http://localhost:3000/
Benchmarking localhost (be patient).....done
...

Requests per second:    9.37 [#/sec] (mean)
Time per request:       1067.630 [ms] (mean)
Time per request:       106.763 [ms] (mean, across all concurrent requests)
Transfer rate:          13.02 [Kbytes/sec] received

Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0    0   0.0      0       0
Processing:  1015 1049  20.2   1057    1067
Waiting:     1015 1048  20.1   1057    1067
Total:       1015 1049  20.2   1058    1067

Percentage of the requests served within a certain time (ms)
  50%   1058
  66%   1065
  75%   1065
  80%   1067
  90%   1067
  95%   1067
  98%   1067
  99%   1067
 100%   1067 (longest request)
          </pre>
        </section>
      </article>

      <article>
        <h3>Wnioski</h3>
        <ul class="build">
          <li>Programowanie współbieżne jest trudne... ale chyba nie do uniknięcia (wszyscy będziemy musieli się kiedyś przestawić - nawet w telefonach mamy już 4 rdzenie)</li>
          <li>Istnieją rozwiązania próbujące ukryć przed programistą część problemów programowania współbieżnego, ale nie wszystkie da się ukryć...</li>
          <li>Warto wiedzieć dlaczego to jest takie skomplikowane</li>
        </ul>
      </article>

      <article>
        <h1>Dziękuję za uwagę</h1>
        <p style="margin-top: 130px">Pytania?</p>
      </article>

      <article>
        <h3>Materiały uzupełniające</h3>
        <ul>
          <li><a href="http://www.gotw.ca/publications/concurrency-ddj.htm">http://www.gotw.ca/publications/concurrency-ddj.htm</a></li>
          <li><a href="http://merbist.com/2011/02/22/concurrency-in-ruby-explained/">http://merbist.com/2011/02/22/concurrency-in-ruby-explained/</a></li>
          <li><a href="http://merbist.com/2011/10/03/about-concurrency-and-the-gil/">http://merbist.com/2011/10/03/about-concurrency-and-the-gil/</a></li>
          <li><a href="http://merbist.com/2011/10/18/data-safety-and-gil-removal/">http://merbist.com/2011/10/18/data-safety-and-gil-removal/</a></li>
          <li><a href="http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/">http://yehudakatz.com/2010/08/14/threads-in-ruby-enough-already/</a></li>
          <li><a href="http://www.igvita.com/2010/06/07/rails-performance-needs-an-overhaul/">http://www.igvita.com/2010/06/07/rails-performance-needs-an-overhaul/</a></li>
          <li><a href="http://blog.headius.com/2008/08/qa-what-thread-safe-rails-means.html">http://blog.headius.com/2008/08/qa-what-thread-safe-rails-means.html</a></li>
          <li><a href="http://confreaks.com/videos/714-rubyconf2011-complex-ruby-concepts-dummified">http://confreaks.com/videos/714-rubyconf2011-complex-ruby-concepts-dummified</a></li>
          <li><a href="http://vimeo.com/38531248">http://vimeo.com/38531248</a></li>
          <li><a href="http://vimeo.com/38994805">http://vimeo.com/38994805</a></li>
        </ul>
      </article>

    </section>
  </body>
</html>
